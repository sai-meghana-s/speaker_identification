# ğŸ™ï¸ Speaker Detection and Identification System

This project detects the **number of speakers** in real-time audio and identifies each speaker by matching their voice against a known voice database.

## âœ… Current Features

- ğŸ”´ Live audio recording via microphone (default 15 seconds)  
- ğŸ§¼ Noise reduction using `noisereduce`  
- ğŸ—£ï¸ Voice Activity Detection (VAD) using `webrtcvad`  
- ğŸ“‚ Modular Python codebase with clean separation of concerns  
- ğŸ¤ Speaker diarization support using `pyannote-audio` (partially integrated)  

## ğŸ“ Project Structure

```
speaker_identification/
â”œâ”€â”€ audio/                 # Handles recording and noise reduction
â”œâ”€â”€ diarization/ # Speaker diarization logic using pyannote-audio
â”œâ”€â”€ vad/                   # Voice Activity Detection module
â”œâ”€â”€ utils/                 # Config settings
â”œâ”€â”€ main.py                # Runs the full pipeline
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ .gitignore # Git ignore file
```


## ğŸš€ How to Run

1. **Clone the repository:**

    ```bash
    git clone https://github.com/yourusername/speaker_identification.git
    cd speaker_identification
    ```

2. **Create and activate a virtual environment:**

    - On Linux/macOS:

      ```bash
      python3 -m venv venv
      source venv/bin/activate
      ```

    - On Windows:

      ```bash
      python -m venv venv
      venv\Scripts\activate
      ```

3. **Install dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

4. **Run the main program:**

    ```bash
    python main.py
    ```

## ğŸ” Authentication for Diarization

- The diarization step uses Hugging Face's `pyannote-audio` models, which require a **Hugging Face API token**.
- Create a free account at [huggingface.co](https://huggingface.co), then generate an access token under **Settings > Access Tokens**.
- Save your token securely and update the `diarization.py` file to use it:

    ```python
    pipeline = Pipeline.from_pretrained(
        "pyannote/speaker-diarization@2.1", 
        use_auth_token="YOUR_HUGGINGFACE_TOKEN"
    )
    ```

---

## ğŸ“Œ Planned Next Steps

- ğŸ§  **Enhance speaker diarization** for better accuracy and realtime processing  
- ğŸ¼ Implement **feature extraction** with `librosa` for improved speaker embeddings  
- ğŸ” Develop a **speaker identification** module leveraging `SpeechBrain` for voice matching  
- ğŸ“Š Add **visualization** of diarization results (e.g., speaker timeline plots)  
- ğŸ§ª Optimize **model compatibility** by managing PyTorch and pyannote versions  

---

